{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFzeXFjz7VBV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Necessary libraries\n",
        "import torch \n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "import torch.nn.functional as F\n",
        "import numpy as np"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tLcGIcVQbxx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Transformation Pipelines\n",
        "\n",
        "transformations = transforms.Compose([\n",
        "                                      transforms.RandomHorizontalFlip(),\n",
        "                                      transforms.RandomRotation(20),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5)),\n",
        "])"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-cidLSaQ-Ah",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2dec84a0-9139-4cf0-d44c-44ea84ac6707"
      },
      "source": [
        "# Loading the train and test dataset\n",
        "train_data = datasets.CIFAR10('cifar-10',train= True, transform= transformations, download= True)\n",
        "test_data = datasets.CIFAR10('cifar-10',train= False, download= True)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yWuA9-afRUvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a8a8ebf6-ab62-477b-c2d4-d105577c5850"
      },
      "source": [
        "len(train_data), len(test_data)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXQFQXW6ReLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a Validation Set from our training dataset\n",
        "\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "\n",
        "# Size of Validation Set\n",
        "validation_size = 0.2\n",
        "\n",
        "# Getting the size of training dataset\n",
        "training_size = len(train_data)\n",
        "\n",
        "# Creating the indices of training size\n",
        "indices = list(range(training_size))\n",
        "\n",
        "# Random Shuffling\n",
        "np.random.shuffle(indices)\n",
        "\n",
        "# Index Split\n",
        "index_split = int(np.floor(training_size * validation_size))\n",
        "\n",
        "# Setting Validation and Training Indices\n",
        "validation_indices, training_indices = indices[:index_split], indices[index_split:]\n",
        "\n",
        "# Sampling\n",
        "\n",
        "training_sample = SubsetRandomSampler(training_indices)\n",
        "validation_sample = SubsetRandomSampler(validation_indices)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOdk0G4gTR28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating DataLoader Object\n",
        "\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "batch_size = 16\n",
        "\n",
        "trainloader = DataLoader(train_data, batch_size= batch_size, sampler= training_sample)\n",
        "testloader = DataLoader(test_data, batch_size= batch_size)\n",
        "validloader = DataLoader(train_data, batch_size= batch_size, sampler= validation_sample)"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ah5j0M-FtUUB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.linear1 = nn.Linear(64 * 4 * 4, 512)\n",
        "        self.linear2 = nn.Linear(512, 10) \n",
        "        self.dropout = nn.Dropout(p=0.3)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = self.pool(F.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 64 * 4 * 4)\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_NJIYOgpS-0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "38be8bd4-1e43-4f7c-bdf0-877b43a9222a"
      },
      "source": [
        "model = CNN()\n",
        "print(model)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNN(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (linear1): Linear(in_features=1024, out_features=512, bias=True)\n",
            "  (linear2): Linear(in_features=512, out_features=10, bias=True)\n",
            "  (dropout): Dropout(p=0.3, inplace=False)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCTYHtB3pVI7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ae2a0921-b480-4760-c5ac-bf9ff23c254a"
      },
      "source": [
        "# Checking if cuda is available or not\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device.type)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wF1HmLjoHxqO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Moving the model to the available device\n",
        "model = model.to(device)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IZLJUAl0H9hi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Adding Loss Function\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Adding Optimizer \n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr= 0.01)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4hpmoxoKoVC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "790e4463-85ab-4eb8-be4f-d7580661b9fa"
      },
      "source": [
        "# Training Loop\n",
        "\n",
        "n_epochs = 5\n",
        "\n",
        "for epoch in range(1, n_epochs + 1):\n",
        "  train_loss = 0.0\n",
        "  valid_loss = 0.0\n",
        "\n",
        "  model.train()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(trainloader):\n",
        "    data, target = data.to(device) , target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_loss += loss.item() * data.size(0)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  for batch_idx, (data, target) in enumerate(validloader):\n",
        "    data, target = data.to(device), target.to(device)\n",
        "    output = model(data)\n",
        "    loss = criterion(output, target)\n",
        "    valid_loss += loss.item() * data.size(0)\n",
        "\n",
        "  train_loss = train_loss/len(trainloader.sampler)\n",
        "  valid_loss = valid_loss/len(validloader.sampler)\n",
        "\n",
        "  print(f'| Epoch: {epoch:02} | Train Loss: {train_loss:.3f} | Val. Loss: {valid_loss:.3f} |')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "| Epoch: 01 | Train Loss: 1.000 | Val. Loss: 0.899 |\n",
            "| Epoch: 02 | Train Loss: 0.976 | Val. Loss: 0.883 |\n",
            "| Epoch: 03 | Train Loss: 0.956 | Val. Loss: 0.881 |\n",
            "| Epoch: 04 | Train Loss: 0.934 | Val. Loss: 0.846 |\n",
            "| Epoch: 05 | Train Loss: 0.918 | Val. Loss: 0.852 |\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}