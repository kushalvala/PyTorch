{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-Building NN",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRkDePLI67bD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing necessary libraries\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import datasets,transforms"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOAEpuHLbbyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating a transform function object to pre-process the incoming image-data\n",
        "\n",
        "transforms = transforms.Compose([transforms.ToTensor(),\n",
        "                                 transforms.Normalize( (0.5,),(0.5,) )])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZasouTe3cO76",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setting the batch_size parameter to chunk our data\n",
        "\n",
        "batch_size = 64\n",
        "\n",
        "# Pulling data from torchvision and applying transformations\n",
        "\n",
        "trainset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download= True, train= True, transform= transforms)\n",
        "trainloader = torch.utils.data.DataLoader(dataset= trainset, batch_size= batch_size, shuffle= True)\n",
        "\n",
        "# Test Dataset\n",
        "\n",
        "testset = datasets.FashionMNIST('~/.pytorch/F_MNIST_data/', download= True, train= False, transform= transforms)\n",
        "testloader = torch.utils.data.DataLoader(dataset= testset, batch_size= batch_size, shuffle= True)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cGFxhMKcdqsx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining a neural network\n",
        "\n",
        "class FashionNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.hidden1 = nn.Linear(784,256)\n",
        "    self.hidden2 = nn.Linear(256,128)\n",
        "    self.output = nn.Linear(128,10)\n",
        "    self.log_softmax = nn.LogSoftmax()\n",
        "    self.activation = nn.ReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.hidden1(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.hidden2(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.output(x)\n",
        "    output = self.log_softmax(x)\n",
        "\n",
        "    return output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z0foqxfktXdr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "4353c187-da19-4bdc-aeb9-fbcfbfa7c1ea"
      },
      "source": [
        "model = FashionNetwork()\n",
        "print(model)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "FashionNetwork(\n",
            "  (hidden1): Linear(in_features=784, out_features=256, bias=True)\n",
            "  (hidden2): Linear(in_features=256, out_features=128, bias=True)\n",
            "  (output): Linear(in_features=128, out_features=10, bias=True)\n",
            "  (log_softmax): LogSoftmax()\n",
            "  (activation): ReLU()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcK2AJYJtZ-6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the loss function: negative log-likelihood loss\n",
        "\n",
        "criterion = nn.NLLLoss()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4d2uy6V_qKPK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ace8718b-12c8-4316-828a-c198793e8332"
      },
      "source": [
        "# Defining an optimizer\n",
        "\n",
        "from torch import optim\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr= 1e-3)\n",
        "\n",
        "print(optimizer.defaults)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'lr': 0.001, 'betas': (0.9, 0.999), 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeZ4mvd8q7NM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "41d683e0-500b-4d31-d312-711f57ee45aa"
      },
      "source": [
        "# Writing the training loop\n",
        "\n",
        "epoch = 10\n",
        "\n",
        "for _ in range(epoch):\n",
        "  running_loss = 0\n",
        "  # Iterating through each image:\n",
        "  for image,label in trainloader:\n",
        "    # Initialising the gradients\n",
        "    optimizer.zero_grad()\n",
        "    # Reshaping the images\n",
        "    image = image.view(image.shape[0], -1)\n",
        "    # Forward Pass of Image\n",
        "    pred = model(image)\n",
        "    # Calculating the loss\n",
        "    loss = criterion(pred,label)\n",
        "    # Calling .backward function on loss\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    running_loss += loss.item()\n",
        "  else:\n",
        "    print(f'Training loss: {running_loss/len(trainloader):.4f}')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training loss: 0.2569\n",
            "Training loss: 0.2463\n",
            "Training loss: 0.2330\n",
            "Training loss: 0.2197\n",
            "Training loss: 0.2110\n",
            "Training loss: 0.2037\n",
            "Training loss: 0.1953\n",
            "Training loss: 0.1853\n",
            "Training loss: 0.1759\n",
            "Training loss: 0.1676\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSIBYBFZy95b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}