{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PyTorch-TorchVision Basics.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjIAwikRXWjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g92hnf75Ypal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2eee227e-29e8-4220-df62-288237970bcc"
      },
      "source": [
        "# Exploring Convolution Operation\n",
        "\n",
        "nn.Conv2d(3,kernel_size=3, out_channels= 16, stride= 2 , padding= 1)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URcUMjLMY--Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        },
        "outputId": "8d028eac-eb7c-4040-e018-796b51dec0cd"
      },
      "source": [
        "# Exploring the Pooling Layers\n",
        "\n",
        "max_pool = nn.MaxPool2d(kernel_size= 3 , stride= 1)\n",
        "\n",
        "a = torch.FloatTensor(3,5,5).random_(0,10)\n",
        "print(a)\n",
        "#print(a.shape)\n",
        "\n",
        "print(max_pool(a))\n",
        "\n",
        "avg_pool = nn.AvgPool2d(kernel_size= 3, stride= 1)\n",
        "\n",
        "print(avg_pool(a))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[5., 9., 8., 4., 6.],\n",
            "         [1., 6., 2., 3., 3.],\n",
            "         [3., 3., 1., 2., 2.],\n",
            "         [9., 2., 0., 5., 0.],\n",
            "         [8., 5., 8., 3., 0.]],\n",
            "\n",
            "        [[6., 6., 5., 5., 9.],\n",
            "         [2., 4., 0., 2., 8.],\n",
            "         [1., 7., 7., 3., 3.],\n",
            "         [8., 7., 2., 1., 1.],\n",
            "         [1., 1., 0., 6., 2.]],\n",
            "\n",
            "        [[1., 4., 3., 3., 5.],\n",
            "         [1., 0., 2., 2., 8.],\n",
            "         [3., 5., 5., 1., 1.],\n",
            "         [6., 6., 9., 7., 0.],\n",
            "         [6., 1., 1., 9., 2.]]])\n",
            "tensor([[[9., 9., 8.],\n",
            "         [9., 6., 5.],\n",
            "         [9., 8., 8.]],\n",
            "\n",
            "        [[7., 7., 9.],\n",
            "         [8., 7., 8.],\n",
            "         [8., 7., 7.]],\n",
            "\n",
            "        [[5., 5., 8.],\n",
            "         [9., 9., 9.],\n",
            "         [9., 9., 9.]]])\n",
            "tensor([[[4.2222, 4.2222, 3.4444],\n",
            "         [3.0000, 2.6667, 2.0000],\n",
            "         [4.3333, 3.2222, 2.3333]],\n",
            "\n",
            "        [[4.2222, 4.3333, 4.6667],\n",
            "         [4.2222, 3.6667, 3.0000],\n",
            "         [3.7778, 3.7778, 2.7778]],\n",
            "\n",
            "        [[2.6667, 2.7778, 3.3333],\n",
            "         [4.1111, 4.1111, 3.8889],\n",
            "         [4.6667, 4.8889, 3.8889]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-5ezVv-wGJM",
        "colab_type": "text"
      },
      "source": [
        "PyTorch cannot process an image pixel directly and needs to have the contents as tensors. To get around this, **torchvision**, being a specialized library for vision and image-related tasks, provides a module calledÂ transform, which provides APIs for converting pixels into tensors, normalizing standard scaling, and so on"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uipRqDIXbwWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "fbc8cac9-8f44-413c-ba08-566e153defab"
      },
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Creating a Tensor From Image\n",
        "\n",
        "print(transforms.ToTensor())\n",
        "\n",
        "# Normalize the Image Tensor\n",
        "\n",
        "print(transforms.Normalize(0.5,0.5))\n",
        "\n",
        "# To resize an image, we use following method\n",
        "\n",
        "print(transforms.Resize((10,10)))\n",
        "\n",
        "# Transform to Crop the Image\n",
        "\n",
        "print(transforms.CenterCrop(10))\n",
        "\n",
        "# Transformations to Pad the image tensors\n",
        "\n",
        "print(transforms.Pad(1,0))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ToTensor()\n",
            "Normalize(mean=0.5, std=0.5)\n",
            "Resize(size=(10, 10), interpolation=PIL.Image.BILINEAR)\n",
            "CenterCrop(size=(10, 10))\n",
            "Pad(padding=1, fill=0, padding_mode=constant)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3JlZcOrywYtJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "10675947-2c51-4efc-d5ac-bf248a322f1c"
      },
      "source": [
        "# To chain multiple transformations\n",
        "\n",
        "transforms.Compose([\n",
        "                    transforms.CenterCrop(10),\n",
        "                    transforms.ToTensor()\n",
        "])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Compose(\n",
              "    CenterCrop(size=(10, 10))\n",
              "    ToTensor()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIF_rcwNzTOK",
        "colab_type": "text"
      },
      "source": [
        "Data augmentation is an important technique in deep learning and computer vision. For any model dealing with deep learning or computer vision, the amount of data available is crucial to see how well the model performs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmOHunQ0ymyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "f93c37fa-09f9-4af1-d93f-8e5e85763b1a"
      },
      "source": [
        "# Cropping a Section of Image Randomly\n",
        "\n",
        "print(transforms.RandomCrop(10))\n",
        "\n",
        "# Randomly Flipping the image Horizontally & Vertically\n",
        "\n",
        "print(transforms.RandomHorizontalFlip(p = 0.3))\n",
        "print(transforms.RandomVerticalFlip(p=0.2))\n",
        "\n",
        "# Adding Brightness,Saturation,Contrast\n",
        "\n",
        "print(transforms.ColorJitter(brightness= 0.2, contrast= 0.4, saturation= 0.3, hue= 0.2))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomCrop(size=(10, 10), padding=None)\n",
            "RandomHorizontalFlip(p=0.3)\n",
            "RandomVerticalFlip(p=0.2)\n",
            "ColorJitter(brightness=[0.8, 1.2], contrast=[0.6, 1.4], saturation=[0.7, 1.3], hue=[-0.2, 0.2])\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}